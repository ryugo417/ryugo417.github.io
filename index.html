<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ryugo Morita - Personal Homepage</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0 auto;
            max-width: 900px;
            padding: 20px;
        }
        nav a {
            margin-right: 15px;
            text-decoration: none;
            color: #333;
        }
        nav a:hover {
            text-decoration: underline;
        }
        img.profile-img {
            border-radius: 50%;
            max-width: 200px;
        }
        section {
            margin-bottom: 40px;
        }
        h2 {
            border-bottom: 2px solid #ddd;
            padding-bottom: 5px;
        }
        ul {
            padding-left: 20px;
        }
    </style>
</head>
<body>

<nav>
    <a href="#about">About Me</a>
    <a href="#research">Research Experience</a>
    <a href="#internship">Internships</a>
    <a href="#publications">Publications</a>
</nav>

<section id="about">
    <h1>Ryugo Morita</h1>
    <img src="tamago.png" alt="Profile Image" class="profile-img">

    <p>
        I am a second-year M.S. student in the Graduate School of Applied Informatics at Hosei University. 
        Currently, I belong to the iMedia Lab led by Assoc. Prof. Jinjia Zhou, where I conduct research on layer-wise image generation and compression in generative models such as diffusion models and GANs. 
        In addition to my work in computer vision, I also engage in HCI research focusing on AI-driven education, exploring how generative AI can enhance learning experiences and cognitive augmentation.
    </p>
    <p>
        <a href="https://scholar.google.com/citations?user=MqJvzUsAAAAJ&hl=ja">Google Scholar</a> | 
        <a href="https://x.com/Oguryu417">Twitter</a> | 
        <a href="https://github.com/ryugo417">Github</a> | 
        <a href="https://www.linkedin.com/in/%E7%AB%9C%E6%A2%A7-%E5%AE%88%E7%94%B0-3391081a6/">LinkedIn</a>
    </p>
</section>

<section id="research">
    <h2>Research Experience</h2>
    <ul>
        <li><strong>SDS DFKI, Germany</strong> (Dec 2023 – Dec 2024)<br>
            Advisor: Prof. Andreas Dengel
            <ul>
                <li>Training-free Chroma Key Content Generation Diffusion Model (CVPR2025)</li>
                <li>Edge-based Denoising Image Compression (EUSIPCO2024)</li>
                <li>GenAIReading (AHs2025)</li>
            </ul>
        </li>
        <li><strong>iMedia Lab, Hosei University</strong> (Apr 2021 – Present)<br>
            Advisor: Assoc. Prof. Jinjia Zhou
            <ul>
                <li>Text-Guided Image Manipulation (WACV2023)</li>
                <li>Background-aware text-to-image synthesis (ICIP2023)</li>
                <li>Background Interpretation-based Foreground Image Synthesize (MIRU2023)</li>
            </ul>
        </li>
    </ul>
</section>

<section id="internship">
    <h2>Internship Experiences</h2>
    <ul>
        <li><strong>SB intuitions</strong> (Mar 2024 – present): Flux model for image editing</li>
        <li><strong>EQUES</strong> (Dec 2023 – present): Research leader for anime generation</li>
        <li><strong>Matsuo Institute</strong> (Oct 2023 – present): Diffusion model for inpainting with Panasonic</li>
        <li><strong>DFKI, Germany</strong> (Dec 2023 – Dec 2024): Diffusion model research</li>
        <li><strong>CyberAgent, Inc.</strong> (Jan 2023 – Dec 2024): Web advertising images generation</li>
        <li><strong>Olympic Broadcasting Services (Paris2024)</strong>: Video editing and translation</li>
        <li><strong>KDDI Research, Inc.</strong> (Dec 2023 – Mar 2024): Edge-based Denoising Image Compression</li>
        <li><strong>DeNA, Inc.</strong> (Aug 2023 – Sep 2023): Baseball data analysis</li>
        <li><strong>Research Center at Hosei University</strong> (Aug 2022 – Dec 2023): Emotion analysis in online classes</li>
        <li><strong>Smart Trade, Inc.</strong> (Aug 2021 – May 2022): Stock price prediction with GAN/LSTM</li>
        <li><strong>Olympic Broadcasting Services (Tokyo2020)</strong>: Video editing and translation</li>
    </ul>
</section>

<section id="publications">
    <h2>Publications</h2>
    <ul>
        <li>
            [1] <strong>TKG-DM: Training-free Chroma Key Content Generation Diffusion Model</strong><br>
            <em><u>Ryugo Morita</u>, Stanislav Frolov, Brian Bernhard Moser, Takahiro Shirakawa, Ko Watanabe, Andreas Dengel, Jinjia Zhou</em><br>
            <span>CVPR 2025 Highlights (Top 13.5%)</span>
        </li>
        <li>
            [2] <strong>Bidirectional Learned Facial Animation Codec for Low Bitrate Talking Head Videos</strong><br>
            <em>Riku Takahashi, <u>Ryugo Morita</u>, Fuma Kimishima, Kosuke Iwama, Jinjia Zhou</em><br>
            <span>DCC 2025</span>
        </li>
        <li>
            [3] <strong>GenAIReading: Augmenting Human Cognition with Interactive Digital Textbooks Using Large Language Models and Image Generation Models</strong><br>
            <em><u>Ryugo Morita</u>, Ko Watanabe, Jinjia Zhou, Andreas Dengel, Shoya Ishimaru</em><br>
            <span>AHs 2025</span>
        </li>
        <li>
            [4] <strong>Edge-based Denoising Image Compression</strong><br>
            <em><u>Ryugo Morita</u>, Hitoshi Nishimura, Ko Watanabe, Andreas Dengel, Jinjia Zhou</em><br>
            <span>EUSIPCO 2024</span>
        </li>
        <li>
            [5] <strong>Learned Measurement Interpolation for Scalable Compressive Sensing</strong><br>
            <em>Manato Shirai, Fuma Kimishima, Jinjia Zhou, <u>Ryugo Morita</u></em><br>
            <span>IJCNN 2024</span>
        </li>
        <li>
            [6] <strong>Visual question answering based evaluation metrics for text-to-image generation</strong><br>
            <em>Mizuki Miyamoto, <u>Ryugo Morita</u>, Jinjia Zhou</em><br>
            <span>ISCAS 2023</span>
        </li>
        <li>
            [7] <strong>Block based Adaptive Compressive Sensing with Sampling Rate Control</strong><br>
            <em>Kosuke Iwama, <u>Ryugo Morita</u>, Jinjia Zhou</em><br>
            <span>ACMM Asia 2023</span>
        </li>
        <li>
            [8] <strong>Dynamic Unilateral Dual Learning for Text to Image Synthesis</strong><br>
            <em>Zhiqiang Zhang, Jiayao Xu, <u>Ryugo Morita</u>, Wenxin Yu, Jinjia Zhou</em><br>
            <span>ACMM Asia 2023</span>
        </li>
        <li>
            [9] <strong>Batinet: Background-aware Text to Image Synthesis and Manipulation Network</strong><br>
            <em><u>Ryugo Morita</u>, Zhiqiang Zhang, Jinjia Zhou</em><br>
            <span>ICIP 2023</span>
        </li>
        <li>
            [10] <strong>Interactive Image Manipulation with Complex Text Instructions</strong><br>
            <em><u>Ryugo Morita</u>, Zhiqiang Zhang, Man M. Ho, Jinjia Zhou</em><br>
            <span>WACV 2023</span>
        </li>
    </ul>
</section>

</body>
</html>
