## Controllable Text-to-Image Generation

### 1.What is this paper about?

It proposes a novel controllable text-to-image generative adversarial network which can effectively synthesise high-quality images and also control parts of the image generation according to natural language descriptions.

### 2.Whatâ€™s better than previous paper?

Previouse one is that the synthetic image would be significantly different from the one generated from the original text when users change some words of a sentence.

It allows parts of the image to be manipulated in correspondence to the modified text description while preserving other unrelated content.

### 3.What are important parts of technique and methods?

![model](../img/Controllable Text-to-Image Generation.jpg) 

1. The word-level spatial and channel-wise attention-driven generator

2. The word-level discriminator

3. The perceptual loss

### 4.How did they verify it?



### 5.Is there a debate?
