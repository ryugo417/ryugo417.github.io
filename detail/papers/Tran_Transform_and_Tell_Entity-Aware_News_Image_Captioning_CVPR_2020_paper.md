## Transform and Tell: Entity-Aware News Image Captioning

### 1.What is this paper about?

An end-to-end model which generates captions for images embedded in news articles.

### 2.Whatâ€™s better than previous paper?

Previous works mainly focus on generic images because they didn't have adequate knowledge such as names and places and couldn't enrich linguistic expression.

It shows not only do news captions describe in detail, but also the associated news articles also provide rich contextual information.
It address the knowledge gap by computing multi-head attention on the words in the article, along with faces and objects that are extracted from the image and the linguistic gap with a flexible byte-pair-encoding that can generate unseen words.

### 3.What are important parts of technique and methods?

![model](../img/.jpg) 



### 4.How did they verify it?



### 5.Is there a debate?