# Generating Natural-Language Video Descriptions Using Text-Mined Knowledge

### 1.What is this paper about?

model to generate images based on detailed visual descriptions using GANs

### 2.What’s better than previous paper?

Our model can in many cases generate visually-plausible 64×64 images conditioned on text, 
but previous model only use GAN for post-processing, our entire model is a GAN

### 3.What are important parts of technique and methods?



### 4.How did they verify it?

We prove it is valid to make images from description for it using the CUB dataset of bird images and the Oxford-102 dataset of flower images.

### 5.Is there a debate?